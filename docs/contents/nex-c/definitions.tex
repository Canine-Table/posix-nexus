\newpage
\section{Definitions}
\label{Definitions}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, secA]
	\begin{NexMainBox}[dark, crnA]
		\begin{NexListDark}
			\NexItemDark{\NexLink{Constants}{Constants}: Includes mathematical, physical, astronomical, and engineering constants.}
			\NexItemDark{\NexLink{Basic Operations}{Basic Operations}: Contains macros for arithmetic, bitwise operations, and geometry.}
			\NexItemDark{\NexLink{Variable Types}{Variable Types}: Definitions of pointers, floating-point types, and integers.}
			\NexItemDark{\NexLink{Endian Macros}{Endian Macros}: Definitions for byte order detection and endian swapping.}
			\NexItemDark{\NexLink{Architecture and Alignment}{Architecture and Alignment}: Macros and types for architecture detection and memory alignment.}
			\NexItemDark{\NexLink{CPU Features}{CPU Features}: Detection of instruction sets, branch prediction, and prefetching capabilities.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\newpage
\subsection{Constants}
\label{Constants}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA]
		This section defines constants for various domains, including mathematical, physical, astronomical, and engineering applications.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA]
		\begin{NexListDark}
			\NexItemDark{\NexLink{Mathematical Constants}{Mathematical Constants}: Includes values like Pi, Tau, and Euler's number.}
			\NexItemDark{\NexLink{Physical Constants}{Physical Constants}: Includes speed of light, Planck's constant, and more.}
			\NexItemDark{\NexLink{Astronomical Constants}{Astronomical Constants}: Includes values like AU, parsec, and solar mass.}
			\NexItemDark{\NexLink{Engineering Constants}{Engineering Constants}: Includes data size units and floating-point precision limits.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\newpage
\subsubsection{Mathematical Constants}
\label{Mathematical Constants}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		Mathematical constants include commonly used values for calculations, such as the golden ratio, Pi, and Euler's number.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Mathematical Constants}}
/* Mathematical Constants */
#define NX_GOLDEN_RATIO 1.618033988749895	/* Golden Ratio (phi) */
#define NX_PI 3.141592653589793			/* Value of Pi */
#define NX_TAU 6.283185307179586		/* Tau (2 * Pi) */
#define NX_E 2.718281828459045			/* Euler's number */
#define NX_SQRT2 1.414213562373095		/* Square root of 2 */
#define NX_LN2 0.6931471805599453		/* Natural logarithm of 2 */
#define NX_LN10 2.302585092994046		/* Natural logarithm of 10 */
\end{NexCodeBox}

\newpage
\subsubsection{Physical Constants}
\label{Physical Constants}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		Physical constants include fundamental values such as the speed of light, Planck's constant, and Boltzmann constant.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Physical Constants}}
/* Physical Constants */
#define NX_LIGHT_SPEED 299792458		/* Speed of light in vacuum (m/s) */
#define NX_GRAVITY 9.80665			/* Standard gravity (m/s^2) */
#define NX_PLANCK 6.62607015e-34		/* Planck's constant (Js) */
#define NX_BOLTZMANN 1.380649e-23		/* Boltzmann constant (J/K) */
#define NX_AVOGADRO 6.02214076e23		/* Avogadro's number (1/mol) */
#define NX_GAS_CONSTANT 8.314462618		/* Ideal gas constant (J/(mol·K)) */
#define NX_ELECTRON_MASS 9.10938356e-31		/* Electron mass (kg) */
#define NX_PROTON_MASS 1.67262192369e-27	/* Proton mass (kg) */
#define NX_ELEM_CHARGE 1.602176634e-19		/* Elementary charge (C) */
#define NX_PERMITTIVITY 8.854187817e-12		/* Vacuum permittivity (F/m) */
#define NX_PERMEABILITY 1.2566370614e-6		/* Vacuum permeability (H/m) */
\end{NexCodeBox}

\newpage
\subsubsection{Astronomical Constants}
\label{Astronomical Constants}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		Astronomical constants include values used for celestial calculations, such as the astronomical unit (AU), parsec, and solar mass.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Astronomical Constants}}
/* Astronomy Constants */
#define NX_AU 149597870700		/* Astronomical Unit (meters) */
#define NX_PARSEC 3.085677581e16	/* Parsec (meters) */
#define NX_SOLAR_MASS 1.989e30		/* Mass of the Sun (kg) */
#define NX_EARTH_MASS 5.972e24		/* Mass of the Earth (kg) */
#define NX_LUNAR_MASS 7.342e22		/* Mass of the Moon (kg) */
#define NX_EARTH_RADIUS 6371000		/* Earth's mean radius (meters) */
#define NX_EARTH_ORBITAL_PERIOD 365.25	/* Earth's orbital period (days) */
#define NX_MOON_DISTANCE 384400000	/* Average Earth-Moon distance (meters) */
\end{NexCodeBox}

\newpage
\subsubsection{Engineering Constants}
\label{Engineering Constants}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		Engineering constants include values such as data size units and floating-point precision limits.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Engineering Constants}}
/* Engineering and Computer Science Constants */
#define NX_KILOBYTE 1024			/* Bytes in a kilobyte */
#define NX_MEGABYTE (1024 * NX_KILOBYTE)	/* Bytes in a megabyte */
#define NX_GIGABYTE (1024 * NX_MEGABYTE)	/* Bytes in a gigabyte */
#define NX_FLOAT_EPSILON 1.19209290e-7		/* Smallest float difference (32-bit) */
#define NX_DOUBLE_EPSILON 2.22044605e-16	/* Smallest double difference (64-bit) */
#define NX_MAX_INT 2147483647			/* Maximum value of a 32-bit int */
#define NX_MIN_INT -2147483648			/* Minimum value of a 32-bit int */
\end{NexCodeBox}

\newpage
\subsection{Basic Operations}
\label{Basic Operations}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA]
		This section includes macros for basic arithmetic operations, bitwise operations, range checks, and geometry-related formulas.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Basic Operations}}
/* Basic Operations */
#define NX_SQUARE_N(N) ((N) * (N))				/* Calculates the square of a number */
#define NX_CUBE_N(N) (NX_SQUARE_N(N) * (N))			/* Calculates the cube of a number */
#define NX_MIN(A, B) ((A) < (B) ? (A) : (B))			/* Returns the minimum of two numbers */
#define NX_MAX(A, B) ((A) > (B) ? (A) : (B))			/* Returns the maximum of two numbers */
#define NX_AVG(A, B) (((A) + (B)) / 2)				/* Calculates the average of two numbers */
#define NX_ODD_N(N) ((N) % 2 == 1)				/* Checks if a number is odd */
#define NX_EVEN_N(N) ((N) % 2 == 0)				/* Checks if a number is even */
#define NX_ABS(N) ((N) < 0 ? -(N) : (N))			/* Returns the absolute value of a number */
#define NX_IS_POWER_OF_TWO(N) ((N) && !((N) & ((N) - 1)))	/* Checks if N is a power of 2 */
\end{NexCodeBox}

\newpage
\subsection{Endian Macros}
\label{Endian Macros}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA]
		Endian macros are used to detect the byte order (endianness) of the platform and provide utilities for converting between big-endian and little-endian formats.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Why does Intel use little-endian while older processors use big-endian?}]
		Intel’s x86 architecture, which became dominant in personal computers, adopted little-endian because it made certain operations easier. Many older systems and RISC-based processors (like PowerPC, SPARC, and older ARM designs) started with big-endian for compatibility with older networking and data transmission standards.
		Big-endian was originally favored because it aligns with how humans typically write numbers—most significant digit first (like \texttt{1234}, not \texttt{4321}). Little-endian, on the other hand, makes certain low-level memory operations more efficient, like reading variable-sized numbers without needing adjustments.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Pros and Cons of Each Endianness}]
		\begin{NexListDark}
			\NexItemDark{\textbf{Big-Endian (Most Significant Byte First)}:
				\begin{NexListLight}
					\NexCheckLight{Easier to read for humans (matches how numbers are written).}
					\NexCheckLight{Often used in networking protocols (big-endian is standard in IP/TCP).}
					\NexXLight{Can require extra steps when handling certain memory operations.}
				\end{NexListLight}
			}
			\NexItemDark{\textbf{Little-Endian (Least Significant Byte First, Used by Intel)}:
				\begin{NexListLight}
					\NexCheckLight{Makes accessing multi-byte numbers more efficient in some cases.}
					\NexCheckLight{Easier to handle variable-length data structures.}
					\NexXLight{Feels counterintuitive when reading raw memory data (since the bytes are in "reverse" order).}
				\end{NexListLight}
			}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA]
		\textbf{Why is it called "Little-Endian"?}
		The term "Little-Endian" comes from Jonathan Swift’s \textit{Gulliver’s Travels}, where people argued over which end of an egg to break first: the Big End or the Little End. Computer scientists borrowed the term to describe data storage formats.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA]
		\textbf{How Does This Relate to Two’s Complement?}
		Two’s complement is a way computers store negative numbers, and while endianness doesn’t affect the math of two’s complement itself, it does influence how the bytes are arranged in memory.
		\begin{NexListDark}
			\NexItemDark{\textbf{Big-Endian:} The sign bit is stored at the beginning.}
			\NexItemDark{\textbf{Little-Endian:} The sign bit is stored at the end.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Endian Macro Definitions}}
/* Endian Macros */
#if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_BIG_ENDIAN__)
	#define NX_BIG_ENDIAN 1
	#define NX_LITTLE_ENDIAN 0
#elif defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
	#define NX_BIG_ENDIAN 0
	#define NX_LITTLE_ENDIAN 1
#elif defined(__BIG_ENDIAN__) || defined(_BIG_ENDIAN) || defined(__ARMEB__) || defined(__MIPSEB__) || defined(__POWERPC__) || defined(__sparc__)
	#define NX_BIG_ENDIAN 1
	#define NX_LITTLE_ENDIAN 0
#else
	#define NX_BIG_ENDIAN 0
	#define NX_LITTLE_ENDIAN 1
#endif

/* Conditional Endian Swap Based on Architecture */
#if NX_BIG_ENDIAN
	#define NX_TO_LITTLE16(X) nx_swap16(X)
	#define NX_TO_LITTLE32(X) nx_swap32(X)
	#define NX_TO_LITTLE64(X) nx_swap64(X)
	#define NX_TO_BIG16(X) (X)  /* Already big-endian */
	#define NX_TO_BIG32(X) (X)
	#define NX_TO_BIG64(X) (X)
#else
	#define NX_TO_LITTLE16(X) (X)  /* Already little-endian */
	#define NX_TO_LITTLE32(X) (X)
	#define NX_TO_LITTLE64(X) (X)
	#define NX_TO_BIG16(X) nx_swap16(X)
	#define NX_TO_BIG32(X) nx_swap32(X)
	#define NX_TO_BIG64(X) nx_swap64(X)
#endif
\end{NexCodeBox}

\subsubsection{Endian Swap Functions}
\label{Endian Swap Functions}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		These inline functions provide utilities for swapping the byte order (endianness) of 16-bit, 32-bit, and 64-bit values. They are useful for ensuring compatibility across architectures with different endianness.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Endian Swap Functions}}
/* Swap 16-bit endian */
static inline nx_u16_t nx_swap16(nx_u16_t v)
{
	return (v >> 8) | (v << 8);
}

/* Swap 32-bit endian */
static inline nx_u32_t nx_swap32(nx_u32_t v)
{
	return ((v >> 24) & 0x000000FF) |
		((v >> 8)  & 0x0000FF00) |
		((v << 8)  & 0x00FF0000) |
		((v << 24) & 0xFF000000);
}

/* Swap 64-bit endian */
static inline nx_u64_t nx_swap64(nx_u64_t v)
{
	return ((v >> 56) & 0x00000000000000FF) |
		((v >> 40) & 0x000000000000FF00) |
		((v >> 24) & 0x0000000000FF0000) |
		((v >> 8)  & 0x00000000FF000000) |
		((v << 8)  & 0x000000FF00000000) |
		((v << 24) & 0x0000FF0000000000) |
		((v << 40) & 0x00FF000000000000) |
		((v << 56) & 0xFF00000000000000);
}
\end{NexCodeBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{What Are These Functions Doing?}]
		These functions take a number in memory and flip the order of its bytes. This is necessary when converting data between big-endian and little-endian systems.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How does nx\_swap32 work? (32-bit swap)}]
		A 32-bit integer is made up of 4 bytes. Imagine it like this:
		\begin{NexMainBox}[light, halign=center]
			Byte0\hspace{1em}|\hspace{1em}Byte1\hspace{1em}|\hspace{1em}Byte2\hspace{1em}|\hspace{1em}Byte3
		\end{NexMainBox}
		In big-endian, it would be stored like this:
		\begin{NexMainBox}[light, halign=center]
			[AB] [CD] [EF] [GH] (Most significant byte first)
		\end{NexMainBox}
		In little-endian, it would be:
		\begin{NexMainBox}[light, halign=center]
			[GH] [EF] [CD] [AB] (Least significant byte first)
		\end{NexMainBox}
		The nx\_swap32 function rearranges the bytes by shifting them left or right, then using bitwise operations (\&) to isolate each chunk before placing it into its new position.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How does nx\_swap64 work? (64-bit swap)}]
		This does the same thing, but for a 64-bit number (which has 8 bytes). It follows the same pattern:
		\begin{NexMainBox}[light, halign=center]
			Byte0 | Byte1 | Byte2 | Byte3 | Byte4 | Byte5 | Byte6 | Byte7
		\end{NexMainBox}
		Just like before, it shifts and isolates bytes to reverse their order.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Why Is This Important?}]
		If you're working on cross-platform applications or network protocols, you might need to convert data between formats to ensure all systems interpret it correctly. That’s why these functions exist—to swap the byte order and avoid misinterpretation.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{What happens when you use >> (bit shifting)?}]
		When you use \texttt{>>}, you’re shifting bits to the right. Each shift moves everything one position to the right, and depending on the system, new bits are filled with either zeros or sign bits.
		\textbf{Example with [AB] [CD] [EF] [GH] (assuming a 32-bit number):}
		\texttt{v >> 8} means everything moves 8 bits to the right:
		\begin{NexMainBox}[light, halign=center]
			Before:  [AB] [CD] [EF] [GH]\\
			After \texttt{>>8}:  [00] [AB] [CD] [EF]  (GH gets pushed out)
		\end{NexMainBox}
		If you shift by 24:
		\begin{NexMainBox}[light, halign=center]
			Before:  [AB] [CD] [EF] [GH]\\
			After \texttt{>>24}:  [00] [00] [00] [AB]  (Only the most significant byte remains)
		\end{NexMainBox}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{What happens when you use \& (bit masking)?}]
		The \texttt{\&} operator compares two numbers bit by bit. If both bits are 1, the result is 1; otherwise, it’s 0.
		\textbf{Example:} \texttt{v \& 0x000000FF} keeps only the last byte, because \texttt{0x000000FF} in binary is:
		\texttt{00000000 00000000 00000000 11111111}
		\begin{NexMainBox}[light, halign=center]
			[AB] [CD] [EF] [GH] \& 00000000 00000000 00000000 11111111\\
			= [00] [00] [00] [GH]
		\end{NexMainBox}
		Essentially, \texttt{\&} helps extract specific parts of the number, while \texttt{>>} moves things around.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How this applies to swapping endianness}]
		The swap functions use:
		\begin{NexListDark}
			\NexItemDark{\texttt{>>} to move bytes into the correct position}
			\NexItemDark{\texttt{\&} to extract only the parts we want before combining them into a new order}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Bitmasking in CIDR notation}]
		CIDR (Classless Inter-Domain Routing) uses bitmasking to define IP address ranges and subnet sizes.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{How Bitmasking Works in CIDR}]
		CIDR notation looks like this: \texttt{192.168.1.0/24}
		The "/24" part is the subnet mask, which means:
		\begin{NexListDark}
			\NexItemDark{The first 24 bits of the IP address are fixed.}
			\NexItemDark{The remaining 8 bits can vary (allowing for 256 possible addresses).}
		\end{NexListDark}
		The subnet mask for /24 in binary:
		\begin{NexMainBox}[light, halign=center]
			11111111 11111111 11111111 00000000  = 255.255.255.0
		\end{NexMainBox}
		Using a bitwise AND (\&) operation, you can filter out the network portion of an IP address.
		\textbf{Example:}
		\begin{NexMainBox}[light, halign=center]
			\begin{verbatim}
IP:	  192.168.1.73	->  11000000 10101000 00000001 01001001
MASK:	255.255.255.0   ->  11111111 11111111 11111111 00000000
-------------------------------------------------------------
Result:  192.168.1.0	 ->  11000000 10101000 00000001 00000000
			\end{verbatim}
		\end{NexMainBox}
		This operation ensures that any device within the subnet keeps the same "network" part of the IP, while only the last portion changes.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title=\textbf{Why Bitmasking is Important in Networking}]
		\begin{NexListDark}
			\NexItemDark{It helps routers quickly determine which subnet an IP belongs to.}
			\NexItemDark{Makes it easy to allocate specific IP ranges to different parts of a network.}
			\NexItemDark{Prevents overlapping IP addresses in large-scale networking.}
		\end{NexListDark}
		So, in essence, CIDR uses bitmasks to group IP addresses together efficiently. That means networking and endianness both rely on shifting and masking bits, but for different reasons!
	\end{NexMainBox}
\end{NexMainBox}

\newpage
\subsection{Architecture and Alignment}
\label{Architecture and Alignment}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA]
		These macros define memory alignment attributes for variables and structures in C. The __attribute__((aligned(N))) directive tells the compiler to ensure that the specified variable or data structure is aligned to an N-byte boundary in memory.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA]
		\begin{NexListDark}
			\NexItemDark{\NexOption{NX_ALIGN_4, NX_ALIGN_8, NX_ALIGN_16, NX_ALIGN_32}: Align data to 4, 8, 16, or 32 bytes, respectively.}
			\NexItemDark{\NexOption{NX_CACHE_ALIGN_64, NX_CACHE_ALIGN_128, NX_CACHE_ALIGN_256}: Align data to cache line sizes of 64, 128, or 256 bytes, respectively.}
			\NexItemDark{\NexOption{NX_IS_64BIT}: Set to \texttt{1} if the system is 64-bit, otherwise set to \texttt{0}.}
			\NexItemDark{\NexOption{nx_size_t}: Defines an unsigned integer type for sizes, appropriate for the architecture.}
			\NexItemDark{\NexOption{nx_ptrdiff_t}: Defines a signed integer type for pointer differences, appropriate for the architecture.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Types of Alignments}]
		\begin{NexListDark}
			\NexItemDark{\textbf{NX_ALIGN_4, NX_ALIGN_8, NX_ALIGN_16, NX_ALIGN_32:}
				\begin{NexListLight}
					\NexCheckLight{Align data to 4, 8, 16, or 32 bytes, respectively.}
					\NexCheckLight{Ensures variables are stored efficiently in memory.}
					\NexCheckLight{Improves CPU performance by avoiding penalties for unaligned memory access.}
				\end{NexListLight}
			}
			\NexItemDark{\textbf{NX_CACHE_ALIGN_64, NX_CACHE_ALIGN_128, NX_CACHE_ALIGN_256:}
				\begin{NexListLight}
					\NexCheckLight{Align data to 64-, 128-, or 256-byte boundaries.}
					\NexCheckLight{Optimizes cache performance by aligning data to cache line sizes.}
					\NexCheckLight{Reduces cache thrashing and improves CPU efficiency.}
				\end{NexListLight}
			}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{Why is Alignment Important?}]
		Alignment is crucial for performance in systems where memory access is optimized for specific boundaries, particularly in:
		\begin{NexListDark}
			\NexItemDark{Embedded systems, where memory and processing resources are constrained.}
			\NexItemDark{High-performance computing, where unaligned memory access can significantly impact throughput.}
			\NexItemDark{SIMD (Single Instruction Multiple Data) operations, which require tightly aligned memory for vectorized processing.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Analogies for Clarity}]
		\begin{NexListDark}
			\NexItemDark{NX_ALIGN_4: Think of this as saying, "Put this data in a spot that’s a multiple of 4 bytes." It’s akin to arranging chocolates in rows of 4 for uniformity and easy access.}
			\NexItemDark{NX_CACHE_ALIGN_64: This is like saying, "Make sure this data fits into a special box that’s 64 bytes big." This helps the computer grab the data faster since it matches the size of its "grabber" (the cache line).}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=Cache Thrashig]
		Cache thrashing happens when a computer keeps swapping data in and out of its cache too often, instead of using it efficiently. This slows things down because the CPU spends more time moving data around than doing actual work.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Think of it like a cluttered desk}]
		Imagine you have a small desk and need a few papers to work on. If you keep shuffling papers on and off the desk because there’s not enough space, you spend more time rearranging than actually working. That's cache thrashing—the CPU keeps replacing data in the cache because it doesn’t fit, making everything slower.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Why does this happen?}]
		\begin{NexListDark}
			\NexItemDark{Not enough cache space: If a program frequently accesses large amounts of data that don’t fit in the cache, it keeps replacing items.}
			\NexItemDark{Poor memory access patterns: Some algorithms keep switching between memory locations instead of accessing them efficiently.}
			\NexItemDark{Conflicting cache lines: If multiple pieces of data keep landing in the same cache slot, they overwrite each other too quickly.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{How to Fix It?}]
		\begin{NexListDark}
			\NexItemDark{Optimize data structures so that frequently accessed data stays close together.}
			\NexItemDark{Use cache-friendly algorithms that avoid unnecessary swaps.}
			\NexItemDark{Increase cache size (if possible) to fit more data at once.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA]
		Basically, cache thrashing is the CPU equivalent of reorganizing your room so much that you never actually get to relax in it!
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Architecture and Alignment Macros}}
/* Architecture Detection */
#if defined(__x86_64__) || defined(_M_X64) || defined(__aarch64__) || defined(__PPC64__) || defined(__mips64)
	#define NX_IS_64BIT 1
	typedef unsigned long long nx_size_t;
	typedef long long nx_ptrdiff_t;
#else
	#define NX_IS_64BIT 0
	typedef unsigned long nx_size_t;
	typedef long nx_ptrdiff_t;
#endif

/* Memory Alignment Macros */
#define NX_ALIGN_4 __attribute__((aligned(4)))   /* Align to 4 bytes */
#define NX_ALIGN_8 __attribute__((aligned(8)))   /* Align to 8 bytes */
#define NX_ALIGN_16 __attribute__((aligned(16))) /* Align to 16 bytes */
#define NX_ALIGN_32 __attribute__((aligned(32))) /* Align to 32 bytes */
#define NX_CACHE_ALIGN_64 __attribute__((aligned(64))) /* Align to 64-byte cache line */
#define NX_CACHE_ALIGN_128 __attribute__((aligned(128))) /* Align to 128-byte cache line */
#define NX_CACHE_ALIGN_256 __attribute__((aligned(256))) /* Align to 256-byte cache line */
\end{NexCodeBox}

\newpage
\subsection{CPU Features}
\label{CPU Features}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA]
		This section includes macros for detecting CPU instruction sets, enabling branch prediction, and optimizing memory access through prefetching.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA]
		\begin{NexListDark}
			\NexItemDark{\NexOption{NX_HAS_SSE}: Set to \texttt{1} if SSE instructions are available, otherwise set to \texttt{0}.}
			\NexItemDark{\NexOption{NX_HAS_AVX}: Set to \texttt{1} if AVX instructions are available, otherwise set to \texttt{0}.}
			\NexItemDark{\NexOption{NX_HAS_NEON}: Set to \texttt{1} if NEON instructions are available, otherwise set to \texttt{0}.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={CPU Features Macros}}
/* CPU Instruction Set Detection */
#if defined(__SSE__) || defined(__x86_64__) || defined(_M_X64)
	#define NX_HAS_SSE 1  /* SSE Instructions Available */
#else
	#define NX_HAS_SSE 0
#endif

#if defined(__AVX__) || defined(__AVX2__) || defined(__x86_64__) || defined(_M_X64)
	#define NX_HAS_AVX 1  /* AVX Instructions Available */
#else
	#define NX_HAS_AVX 0
#endif

#if defined(__ARM_NEON) || defined(__ARM_FEATURE_NEON)
	#define NX_HAS_NEON 1 /* NEON Instructions Available (ARM) */
#else
	#define NX_HAS_NEON 0
#endif

#if defined(__CACHE_LINE_SIZE)
	#define NX_CACHE_LINE_SIZE __CACHE_LINE_SIZE /* Cache line size */
#elif defined(__GNUC__) && defined(__x86_64__)
	#include <unistd.h>
	#define NX_CACHE_LINE_SIZE sysconf(_SC_LEVEL1_DCACHE_LINESIZE) /* Retrieve cache line size */
#else
	#define NX_CACHE_LINE_SIZE 64 /* Default to 64 bytes (common architecture) */
#endif

/* Branch Prediction Macros */
#if defined(__GNUC__) || defined(__clang__)
	#define NX_LIKELY(x) __builtin_expect(!!(x), 1) /* Likely branch */
	#define NX_UNLIKELY(x) __builtin_expect(!!(x), 0) /* Unlikely branch */
#else
	#define NX_LIKELY(x) (x) /* No prediction available */
	#define NX_UNLIKELY(x) (x)
#endif

/* Instruction Prefetching */
#if defined(__GNUC__) || defined(__clang__)
	#define NX_PREFETCH(addr) __builtin_prefetch(addr)
#elif defined(_MSC_VER)
	#include <mmintrin.h}
	#define NX_PREFETCH(addr) _mm_prefetch((const char *)(addr), _MM_HINT_T0)
#else
	#define NX_PREFETCH(addr) /* No prefetch available */
#endif
\end{NexCodeBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{What is SSE (Streaming SIMD Extensions)?}]
		SSE (Streaming SIMD Extensions) is a set of CPU instructions designed to improve performance when handling vectorized operations, especially for multimedia, gaming, and scientific computing. \textbf{SIMD} (Single Instruction, Multiple Data) means the CPU can apply the same operation to multiple data elements simultaneously—great for speed!
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Key Features of SSE Instructions}]
		\begin{NexListDark}
			\NexItemDark{\textbf{Parallel Processing:} SSE allows the CPU to process multiple numbers at once, instead of one at a time.}
			\NexItemDark{\textbf{Floating-Point Optimization:} Speeds up tasks involving floating-point calculations, such as graphics rendering, physics simulations, and audio processing.}
			\NexItemDark{\textbf{Enhanced Vector Math:} Ideal for operations on arrays of numbers—common in physics engines, machine learning, image processing, and more.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Evolution of SSE}]
		Intel introduced SSE with the Pentium III (1999), and expanded it over time:
		\begin{NexListDark}
			\NexItemDark{\textbf{SSE (1999):} Introduced 128-bit registers for floating-point calculations.}
			\NexItemDark{\textbf{SSE2 (2001):} Added support for integer operations alongside floating-point.}
			\NexItemDark{\textbf{SSE3 (2004):} Improved multimedia performance and added horizontal operations.}
			\NexItemDark{\textbf{SSSE3 (2006):} Advanced shuffle and blend operations for greater efficiency.}
			\NexItemDark{\textbf{SSE4 (2007-2008):} Added text processing optimizations and more arithmetic functions.}
			\NexItemDark{\textbf{AVX (2011+):} The successor to SSE, introducing 256-bit vector registers for even faster computation.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Real-World Uses of SSE}]
		\begin{NexListDark}
			\NexItemDark{Video encoding/decoding (e.g., accelerating codecs like H.264)}
			\NexItemDark{Game physics calculations (e.g., handling objects in motion)}
			\NexItemDark{AI and deep learning (matrix multiplications)}
			\NexItemDark{Image processing and graphics rendering}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA]
		In short, SSE makes complex mathematical operations much faster by allowing multiple calculations to happen at once instead of one at a time!
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{What is AVX (Advanced Vector Extensions)?}]
		AVX (Advanced Vector Extensions) is a set of CPU instructions that extends the capabilities of SSE (Streaming SIMD Extensions) to allow even more powerful parallel processing and high-performance computing. AVX is especially useful for workloads involving heavy mathematical calculations, like scientific simulations, deep learning, and multimedia processing.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How AVX Improves Performance}]
		Compared to SSE, AVX:
		\begin{NexListDark}
			\NexItemDark{Uses 256-bit registers (instead of 128-bit in SSE), allowing double the amount of data to be processed at once.}
			\NexItemDark{Introduces new floating-point operations, boosting performance for graphics rendering, physics simulations, and machine learning.}
			\NexItemDark{Supports fused multiply-add (FMA) operations, letting the CPU perform multiplication and addition in a single step—saving both time and energy.}
		\end{NexListDark}
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title=\textbf{Evolution of AVX}]
		AVX has evolved through multiple generations:
		\begin{NexListDark}
			\NexItemDark{\textbf{AVX (2011):} Introduced 256-bit vector processing, ideal for floating-point calculations.}
			\NexItemDark{\textbf{AVX2 (2013):} Added integer processing and better memory handling, improving workloads like video encoding and matrix operations.}
			\NexItemDark{\textbf{AVX-512 (2017):} Uses 512-bit registers, supporting even larger parallel computations (common in high-performance computing and AI).}
		\end{NexListDark}
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title=\textbf{Real-World Uses of AVX}]
		\begin{NexListDark}
			\NexItemDark{Cryptography – Encrypting and decrypting data efficiently.}
			\NexItemDark{Machine learning – Accelerating deep learning operations.}
			\NexItemDark{Video processing – Faster encoding and decoding.}
			\NexItemDark{Scientific simulations – Modeling physics, fluid dynamics, and more.}
		\end{NexListDark}
	\end{NexMainBox}

\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA]
		Basically, AVX is SSE on steroids, making CPU calculations way faster and more efficient.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecA]
	\begin{NexMainBox}[dark, crnA, title={What is FMA (Fused Multiply-Add)?}]
		FMA stands for \textbf{Fused Multiply-Add}, a specialized CPU instruction that performs multiplication and addition in a single step. This improves both efficiency and precision in mathematical computations, especially in areas like graphics, physics simulations, machine learning, and scientific computing.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title={How Does FMA Work?}]
		Instead of computing:
		\begin{NexCodeBox}{c}{inA}
result = (a * b) + c;
		\end{NexCodeBox}
		as two separate operations (multiplication followed by addition), FMA combines both into a single instruction:
		\begin{NexCodeBox}{c}{inA}
result = FMA(a, b, c);
		\end{NexCodeBox}

		\textbf{Why is this better?}
		\begin{NexListDark}
			\NexItemDark{Normally, CPUs round after each arithmetic operation, which can reduce precision.}
			\NexItemDark{With FMA, the multiplication and addition happen together, with only one rounding at the end.}
			\NexItemDark{This reduces precision loss and improves accuracy.}
		\end{NexListDark}
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title={Why is FMA Important?}]
		\begin{NexListDark}
			\NexCheckDark{Improves Performance – FMA can process calculations twice as fast compared to separate multiplication and addition.}
			\NexCheckDark{Reduces Rounding Errors – Floating-point math suffers from precision loss due to repeated rounding; FMA minimizes this.}
			\NexCheckDark{Optimized for Vectorized Math – Works great in SIMD instruction sets like AVX, AVX2, and AVX-512, making complex computations much faster.}
		\end{NexListDark}
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title={Where is FMA Used?}]
		\begin{NexListDark}
			\NexItemDark{Computer Graphics \& Game Engines – Faster lighting and physics calculations.}
			\NexItemDark{Machine Learning \& AI – Accelerating matrix multiplications.}
			\NexItemDark{Cryptography – Efficient mathematical computations in encryption algorithms.}
			\NexItemDark{Scientific Simulations – Fluid dynamics, particle physics, financial modeling.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}


\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{What is NEON?}]
		NEON is ARM's SIMD (Single Instruction, Multiple Data) extension, designed to accelerate tasks like multimedia processing, cryptography, AI computations, and gaming on ARM-based processors (which are found in most smartphones and embedded systems).
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{What Makes NEON Special?}]
		\begin{NexListDark}
			\NexItemDark{\textbf{Vector Processing:} NEON can process multiple data elements in parallel, making it much faster than handling data one-by-one.}
			\NexItemDark{\textbf{Optimized for Mobile:} Unlike Intel’s SSE and AVX, NEON is tailored for ARM-based CPUs, commonly used in mobile devices, tablets, and embedded systems.}
			\NexItemDark{\textbf{Efficient Floating-Point and Integer Computation:} Speeds up operations like image filters, audio processing, physics calculations, and machine learning inference.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How NEON Improves Performance}]
		Imagine you need to add up multiple pairs of numbers:
		\begin{NexListDark}
			\NexItemDark{A regular CPU would do one addition at a time.}
			\NexItemDark{NEON can process multiple additions at once using vectorized instructions.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{NEON vs. SSE/AVX}]
		\begin{NexListDark}
			\NexItemDark{SSE/AVX (on x86 processors) also do SIMD, but AVX supports 256-bit and 512-bit registers for even higher parallelism.}
			\NexItemDark{NEON (on ARM processors) uses 128-bit registers, optimized for lower power consumption (great for mobile devices).}
			\NexItemDark{NEON is more power-efficient, making it the preferred SIMD option for smartphones and embedded systems.}
		\end{NexListDark}
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Where NEON is Used}]
		\begin{NexListDark}
			\NexItemDark{Graphics \& Image Processing – Filters, scaling, transformations}
			\NexItemDark{Audio Processing – Sound effects, speech recognition}
			\NexItemDark{Cryptography – Secure hashing and encryption operations}
			\NexItemDark{Machine Learning – Accelerating deep learning inference}
			\NexItemDark{Physics Engines – Collision detection in mobile games}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{How SIMD Instructions Use Large Registers}]
		When we talk about SSE being 128-bit or AVX being 256-bit, we’re referring to special registers inside the CPU designed for vectorized operations (\textbf{SIMD}: Single Instruction, Multiple Data).

		Even if the CPU architecture is 64-bit, it still has dedicated SIMD registers (like \textbf{XMM} for SSE and \textbf{YMM} for AVX) that hold larger chunks of data at once.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title=\textbf{Example: SIMD Register Capacity}]
		Let’s say we’re doing math on four 32-bit numbers at once:
		\begin{NexListDark}
			\NexItemDark{A normal CPU register (64-bit) would only hold two 32-bit numbers.}
			\NexItemDark{An SSE register (128-bit) can hold four 32-bit numbers.}
			\NexItemDark{An AVX register (256-bit) can hold eight 32-bit numbers!}
		\end{NexListDark}
		This lets the CPU process multiple data points in a single instruction, improving speed for tasks like image processing, AI computations, and physics simulations.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title=\textbf{Architectural Bits vs. SIMD Bits}]
		\begin{NexListDark}
			\NexItemDark{\textbf{Architecture} (16-bit, 32-bit, 64-bit) refers to general CPU capabilities like memory addressing and instruction execution.}
			\NexItemDark{\textbf{SSE and AVX registers} are special-purpose registers inside the CPU designed to handle larger data chunks, independently of the standard architecture.}
		\end{NexListDark}
		That’s how a 64-bit CPU can still have 128-bit SSE and 256-bit AVX instructions—they’re simply using separate vector registers for fast parallel computation!
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{Cache Line Size (\texttt{NX_CACHE_LINE_SIZE})}]
		This macro defines the size of a cache line—the smallest chunk of memory a CPU loads into the cache when accessing data.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title=\textbf{How the Macro Works}]
		\begin{NexListDark}
			\NexItemDark{If the system provides \texttt{__CACHE_LINE_SIZE}, we use it.}
			\NexItemDark{If using GNU C and x86_64, it retrieves the L1 data cache line size via \texttt{sysconf(_SC_LEVEL1_DCACHE_LINESIZE)}.}
			\NexItemDark{Otherwise, we default to 64 bytes, a common cache line size in modern processors.}
		\end{NexListDark}
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA, title=\textbf{Why Does Cache Line Size Matter?}]
		Efficient cache use minimizes cache thrashing and improves memory access speed. If data structures are aligned properly to match the cache line size, we reduce unnecessary cache misses and improve performance.
	\end{NexMainBox}
	\begin{NexMainBox}[dark, crnA, title={Branch Prediction Macros (NX_LIKELY and NX_UNLIKELY)}]
		Branch prediction is a CPU technique that tries to guess which way an \texttt{if} statement or loop condition will go.

		\texttt{__builtin_expect(x, 1)} tells the compiler that \texttt{x} is very likely to be true.

		\texttt{__builtin_expect(x, 0)} tells the compiler that \texttt{x} is unlikely to be true.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title={Why is this important?}]
		CPUs use pipelines to execute instructions efficiently. If the CPU incorrectly predicts a branch, it must flush its pipeline and restart—hurting performance.

		Using branch prediction hints helps the compiler generate optimized machine code, reducing the number of branch mispredictions.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={Branch Prediction Example}}
if (NX_LIKELY(value > 0)) {
	// Fast path: Most of the time, value is > 0
} else {
	// Slow path: Rare case
}
\end{NexCodeBox}

\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, ssecB]
	\begin{NexMainBox}[dark, crnA]
		This allows the CPU to optimize for the most common case, improving execution speed.
	\end{NexMainBox}

	\begin{NexMainBox}[dark, crnA, title={Final Thoughts}]
		Both cache line optimizations and branch prediction hints help squeeze extra performance out of the CPU by minimizing wasted cycles. The goal is to make memory access efficient and ensure the processor doesn't waste time on incorrect predictions.
	\end{NexMainBox}
\end{NexMainBox}

\newpage
\subsubsection{CPU Core Detection}
\label{CPU Core Detection}
\begin{NexMainBox}[light, hdrA, sdwA, crnA, grwB, sssecA]
	\begin{NexMainBox}[dark, crnA]
		This inline function retrieves the number of logical CPU cores on the current system. On macOS, it uses the \texttt{sysctlbyname} function to query the \texttt{hw.logicalcpu} property.
	\end{NexMainBox}
\end{NexMainBox}

\begin{NexCodeBox}{c}{title={CPU Core Detection Function}}
#ifndef NX_CPU_CORES
static inline nx_u32_t nx_cpu_cores()
{
	nx_u32_t c;
	nx_size_t s = sizeof(c);
	sysctlbyname("hw.logicalcpu", &c, &s, NX_NULL, 0);
	return c;
}
#define NX_CPU_CORES nx_cpu_cores()
#endif
\end{NexCodeBox}


